{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07927e79",
   "metadata": {},
   "source": [
    "# Denoising\n",
    "\n",
    "In this notebook, we demonstrate the denoising capability of `phase2vec` over and above a LASSO baseline. You can choose the type of of noise you'd like, generate the data and compare the ability of `phase2vec` to reproduce clean parameters and velocities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2789a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from phase2vec.utils import get_command_defaults, ensure_dir, write_yaml, update_yaml\n",
    "from phase2vec.train import load_model, train_model, run_epoch\n",
    "from phase2vec.data import load_dataset, SystemFamily\n",
    "from phase2vec.train._losses import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da8a5a",
   "metadata": {},
   "source": [
    "## Generate noisy data\n",
    "First we generate noisy data. Include the systems you'd like in the list `noise_data_names` and then edit `noise_type` and `noise_mag` to adjust the style and strength of noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate data\n",
    "outdir = '../output/' # Alter to change where all of the phase2vec data will be saved. \n",
    "data_dir = os.path.join(outdir, 'data')\n",
    "\n",
    "# Edit the data included in training and testing here. \n",
    "noise_data_names  = ['saddle_node', 'pitchfork', 'transcritical',\n",
    "                    'selkov', 'homoclinic', 'vanderpol',\n",
    "                    'simple_oscillator', 'fitzhugh_nagumo', 'lotka_volterra']\n",
    "\n",
    "# Edit the type of noise here\n",
    "noise_type = 'trajectory' #'gaussian', 'masking', 'parameter'\n",
    "noise_mag=2000 # for \"trajectory\", the bigger the integer, the less noise; for other types of noise, the bigger the float, the bigger the noise.\n",
    "tt = 1.0\n",
    "alpha = .01\n",
    "device='cpu'\n",
    "num_samples = 100\n",
    "\n",
    "noise_system_classes = []\n",
    "for system in [SystemFamily(data_name=name) for name in noise_data_names]:\n",
    "    noise_system_classes += [system.data_name + ' ' + str(i) for i in range(len(system.param_groups))]\n",
    "\n",
    "samplers    = ['uniform'] * len(noise_data_names)\n",
    "props       = [str(1. / len(noise_data_names))] * len(noise_data_names)\n",
    "noise_data_names   = '-s ' +  ' -s '.join(noise_data_names)\n",
    "samplers     = '-sp ' +  ' -sp '.join(samplers)\n",
    "props = '-c ' +  ' -c '.join(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate noisy data\n",
    "subprocess.call(f'phase2vec generate-dataset --data-dir {data_dir} --data-set-name classical_noise_type_{noise_type}_mag_{noise_mag} --noise-type {noise_type} --noise-mag {noise_mag} --num-samples {num_samples} {noise_data_names} {samplers} {props} --tt {tt} --alpha {alpha} ', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c49434",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate clean data\n",
    "subprocess.call(f'phase2vec generate-dataset --data-dir {data_dir} --data-set-name classical_no_noise --num-samples {num_samples} {noise_data_names} {samplers} {props}', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee8e9c",
   "metadata": {},
   "source": [
    "Next we load each data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load noisy data\n",
    "noisy_data_path = os.path.join(data_dir, f'classical_noise_type_{noise_type}_mag_{noise_mag}')\n",
    "X_noisy1, X_noisy2, y_noisy1, y_noisy2, p_noisy1, p_noisy2 = load_dataset(noisy_data_path)\n",
    "X_noisy = np.concatenate([X_noisy1, X_noisy2])\n",
    "y_noisy = np.concatenate([y_noisy1, y_noisy2])\n",
    "p_noisy = np.concatenate([p_noisy1, p_noisy2])\n",
    "\n",
    "# Load clean data\n",
    "clean_data_path = os.path.join(data_dir, f'classical_no_noise')\n",
    "X_clean1, X_clean2, y_clean1, y_clean2, p_clean1, p_clean2 = load_dataset(clean_data_path)\n",
    "X_clean = np.concatenate([X_clean1, X_clean2])\n",
    "y_clean = np.concatenate([y_clean1, y_clean2])\n",
    "p_clean = np.concatenate([p_clean1, p_clean2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881af2c",
   "metadata": {},
   "source": [
    "# Load model and evaluate\n",
    "\n",
    "We now load a pretrained model which we assume was saved under the name `sparse_train_<beta>` where `beta` is the value used during the training period. You can edit the variable `beta` or the model save directory directly if the model was saved elsewhere. These values are set to match the default values in the `train_and_eval` notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set net parameters\n",
    "from phase2vec.cli._cli import generate_net_config\n",
    "\n",
    "beta = 1e-3\n",
    "net_info = get_command_defaults(generate_net_config)\n",
    "model_type = net_info['net_class']\n",
    "model_save_dir  = os.path.join(outdir, f'models/sparse_train_{beta}')\n",
    "\n",
    "# These parameters are not considered architectural parameters for the net, so we delete them before they're passed to the net builder. \n",
    "del net_info['net_class']\n",
    "del net_info['output_file']\n",
    "del net_info['pretrained_path']\n",
    "del net_info['ae']\n",
    "\n",
    "net = load_model(model_type, pretrained_path=os.path.join(model_save_dir, 'model.pt'), device=device, **net_info).to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ddec6",
   "metadata": {},
   "source": [
    "Here are a few helper functions that make it easier to compare `phase2vec` and `lasso`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_p2v(net, data):\n",
    "    b = data.shape[0]\n",
    "    n = data.shape[2]\n",
    "    emb  = net.emb(net.enc(data).reshape(b, -1))\n",
    "    out  = net.dec(emb)\n",
    "    pars = out.reshape(-1,net.library.shape[-1], 2)\n",
    "    recon = torch.einsum('sl,bld->bsd',net.library.to(device),pars).reshape(b, n,n,2).permute(0,3,1,2)\n",
    "    return pars, recon\n",
    "\n",
    "def forward_lasso(net, data):\n",
    "    b = data.shape[0]\n",
    "    n = data.shape[2]\n",
    "    # LASSO\n",
    "    pars = []\n",
    "    for z in data:\n",
    "        zx = z[0,:,:].numpy().flatten()\n",
    "        zy = z[1,:,:].numpy().flatten()\n",
    "        clf = linear_model.Lasso(alpha=1e-3)\n",
    "        clf.fit(net.library.numpy(), zx)\n",
    "        mx = clf.coef_\n",
    "        clf.fit(net.library.numpy(), zy)\n",
    "        my = clf.coef_\n",
    "        pars.append(torch.stack([torch.tensor(mx), torch.tensor(my)]))\n",
    "    pars = torch.stack(pars).permute(0,2,1)\n",
    "    recon = torch.einsum('sl,bld->bsd',net.library.to(device),pars).reshape(b,n,n,2).permute(0,3,1,2)  \n",
    "    return pars, recon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efa661",
   "metadata": {},
   "source": [
    "## Evaluate average performance on each system, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1139a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "import pdb\n",
    "\n",
    "# Places to store intermediate results\n",
    "loss_dict = {}\n",
    "sorted_data = []\n",
    "sorted_data_clean = []\n",
    "recon_dict = {'p2v':[],'lasso':[]}\n",
    "fp_normalize = True\n",
    "\n",
    "# Set loss\n",
    "euclidean = normalized_euclidean if fp_normalize else euclidean_loss\n",
    "\n",
    "# Don't forget this part!\n",
    "net.eval()\n",
    "for label in tqdm(np.unique(y_noisy)):\n",
    "    \n",
    "    # Noisy data for this class\n",
    "    data_noisy   = torch.tensor([datum for (d, datum) in enumerate(X_noisy) if y_noisy[d] == label])\n",
    "    pars_noisy   = torch.tensor([par for (p, par) in enumerate(p_noisy) if y_noisy[p] == label])\n",
    "    labels = torch.ones(len(data_noisy)) * label\n",
    "    \n",
    "    sorted_data += list(data_noisy)\n",
    "    \n",
    "    # Clean data for this class\n",
    "    data_clean   = torch.tensor([datum for (d, datum) in enumerate(X_clean) if y_clean[d] == label])\n",
    "    pars_clean   = torch.tensor([par for (p, par) in enumerate(p_clean) if y_clean[p] == label])\n",
    "    labels_clean = torch.ones(len(data_clean)) * label\n",
    "    \n",
    "    sorted_data_clean += list(data_clean)\n",
    "    \n",
    "    # Both the p2v and lasso loss for this class\n",
    "    class_par_losses = []\n",
    "    class_recon_losses = []\n",
    "    # For each fitting method\n",
    "    for nm, forward in zip(recon_dict.keys(),[forward_p2v, forward_lasso]):\n",
    "        \n",
    "        # Fit pars and return recon\n",
    "        pars_fit, recon = forward(net, data_noisy.float())\n",
    "    \n",
    "        # Par loss\n",
    "        par_loss   = euclidean_loss(pars_fit, pars_clean).detach().cpu().numpy()\n",
    "        # Recon loss\n",
    "        recon_loss = euclidean(recon, data_clean).detach().cpu().numpy()\n",
    "        class_par_losses.append(par_loss)\n",
    "        class_recon_losses.append(recon_loss) \n",
    "        \n",
    "        recon_dict[nm] += list(recon)    \n",
    "    loss_dict[noise_system_classes[label]] = class_recon_losses + class_par_losses\n",
    "df = pd.DataFrame(data=loss_dict)\n",
    "df.index = [ 'Recon-P2V', 'Recon-LASSO', 'Param-P2V', 'Param-LASSO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data frame of results\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7726934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average performance of phase2vec vs lasso\n",
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4f634",
   "metadata": {},
   "source": [
    "## Visualize Reconstructions\n",
    "Finally, we visualize some randomly sampled vector fields and their reconstructions via both `phase2vec` and LASSO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embedding inds\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pdb\n",
    "\n",
    "num_data = X_noisy.shape[0]\n",
    "num_lattice = X_noisy.shape[2]\n",
    "\n",
    "x = np.linspace(-1.0,1.0, num_lattice)\n",
    "y = np.linspace(-1.0,1.0,num_lattice)\n",
    "\n",
    "num_vis = 4\n",
    "vis_inds = np.random.permutation(num_data)[:num_vis]\n",
    "fig, axes = plt.subplots(4,4,figsize=(12,12))\n",
    "\n",
    "vis_data = [sorted_data[ind].detach().numpy() for ind in vis_inds]\n",
    "vis_clean = [sorted_data_clean[ind].detach().numpy() for ind in vis_inds]\n",
    "vis_recons_lasso = [recon_dict['lasso'][ind].detach().numpy() for ind in vis_inds]\n",
    "vis_recons_p2v = [recon_dict['p2v'][ind].detach().numpy() for ind in vis_inds]\n",
    "\n",
    "for a, (col, clean, noisy, recon_lasso, recon_p2v) in enumerate(zip(axes.T, vis_clean, vis_data, vis_recons_lasso, vis_recons_p2v)):\n",
    "    for row, arr, nm in zip(col, [clean, noisy, recon_lasso, recon_p2v], ['Clean', 'Noisy', 'Recon-LASSO', 'Recon-P2V']):\n",
    "        arr = arr.transpose(0,2,1)\n",
    "\n",
    "        row.streamplot(x,y,arr[0],arr[1],color=(arr**2).sum(0), cmap='hot')\n",
    "        if a == 0:\n",
    "            row.set_ylabel(nm)\n",
    "    for ax in col:\n",
    "        ax.grid(b=None)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c49e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
