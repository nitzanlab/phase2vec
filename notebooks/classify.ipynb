{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07927e79",
   "metadata": {},
   "source": [
    "# Classify embeddings\n",
    "\n",
    "This notebook can be used to recreate Fig. 4 from the manuscript. We compute and classify embeddings for several vector field datasets using a pretrained model. \n",
    "\n",
    "Our coding framework is based on a Click interface and we make use of that in this notebook by running the basic steps in the pipeline through shell commands.note\n",
    "\n",
    "**NOTE**: This notebook assumes you have a pretrained model. You can train a model using the notebook `train_and_eval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2789a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from src.utils import get_command_defaults, ensure_dir, write_yaml, update_yaml\n",
    "from src.train import load_model, train_model, run_epoch\n",
    "from src.data import load_dataset, SystemFamily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da8a5a",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "First, we generate the relevant evaluation data. There are three datasets immediately available here: (1) linear (e.g. fixed point classification), (2) conservative vs non-conservative and (3) incompressible vs compressible. You can comment out the `eval_data_names` definitions to switch between experiments.\n",
    "\n",
    "First, we set the data generation parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851c66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate evaluation data\n",
    "\n",
    "data_dir = '/home/mgricci/data/phase2vec' # Alter to change where all of the phase2vec data will be saved. \n",
    "\n",
    "# Switch between evaluation sets here\n",
    "# eval_data_names  = ['linear']\n",
    "# eval_data_names  = ['conservative', 'polynomial']\n",
    "# eval_data_names  = ['incompressible', 'polynomial']\n",
    "eval_data_names  = ['incompressible', 'conservative','polynomial']\n",
    "\n",
    "data_set_name = 'physics_3class'\n",
    "\n",
    "# Get class names\n",
    "eval_system_classes = []\n",
    "for system in [SystemFamily(data_name=name) for name in eval_data_names]:\n",
    "    eval_system_classes += [system.data_name + ' ' + str(i) for i in range(system.num_classes)]\n",
    "\n",
    "num_eval_classes = len(eval_system_classes)\n",
    "\n",
    "# Edit the number of total samples from each data set here.\n",
    "#By default, each set is divied further into a base and validation set at a 75/100 split. This can be altered below. \n",
    "num_eval_samples = 1000 # total number of train/val samples\n",
    "device            = 'cpu' # set to `cpu` if cuda not available\n",
    "\n",
    "eval_samplers    = ['uniform'] * len(eval_data_names)\n",
    "eval_props       = [str(1. / len(eval_data_names))] * len(eval_data_names)\n",
    "eval_system_names   = '-s ' +  ' -s '.join(eval_data_names)\n",
    "eval_samplers     = '-sp ' +  ' -sp '.join(eval_samplers)\n",
    "eval_props = '-c ' +  ' -c '.join(eval_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881af2c",
   "metadata": {},
   "source": [
    "Next, we call the actual shell commands for generating the data. These commands will make two directories, called `polynomial` and `classical`, corresponding to train and test sets, inside your `data_dir`. \n",
    "\n",
    "In order to alter the validation proportion, $p$, add the flag `--val-size <p>` where $p\\in (0,1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c484a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating incompressible data.\n",
      "Generating conservative data.\n",
      "Generating polynomial data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(f'phase2vec generate-dataset --data-dir {data_dir} --data-set-name {data_set_name} --num-samples {num_eval_samples} {eval_samplers} {eval_props} {eval_system_names}', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a948e1",
   "metadata": {},
   "source": [
    "## Load `phase2vec` encoder. \n",
    "\n",
    "We load the embedding CNN. By default, the net is saved in the folder `basic_train`, which is the default directory given in the `train_and_eval` notebook. \n",
    "\n",
    "* **model_type** (str): which of the pre-built architectures from _models.py to load. Make your own by combining modules from _modules.py \n",
    "* **latent_dim** (int): embedding dimension\n",
    "* Continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854d71bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Set net parameters\n",
    "from src.cli._cli import generate_net_config\n",
    "\n",
    "net_info = get_command_defaults(generate_net_config)\n",
    "model_type = net_info['net_class']\n",
    "model_save_dir  = os.path.join('/home/mgricci/phase2vec/', 'basic_train')\n",
    "\n",
    "# These parameters are not considered architectural parameters for the net, so we delete them before they're passed to the net builder. \n",
    "del net_info['net_class']\n",
    "del net_info['output_file']\n",
    "del net_info['pretrained_path']\n",
    "del net_info['ae']\n",
    "\n",
    "\n",
    "net = load_model(model_type, pretrained_path=os.path.join(model_save_dir, 'model.pt'), device=device, **net_info).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80583ef7",
   "metadata": {},
   "source": [
    "## Load data and compute embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17cca4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is evaluation data stored? \n",
    "eval_data_path = os.path.join(data_dir, 'physics_3class')\n",
    "\n",
    "# Load evaluation data. \n",
    "X_train, X_test, y_train, y_test, p_train, p_test = load_dataset(eval_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84192ec",
   "metadata": {},
   "source": [
    "Now, we compute and save the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f5a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results_dir = f'/home/mgricci/results/phase2vec/{eval_data_names[0]}'\n",
    "ensure_dir(results_dir)\n",
    "\n",
    "for i, (name, data, labels, pars) in enumerate(zip(['train', 'test'], [X_train, X_test],[y_train, y_test],[p_train, p_test])):\n",
    "\n",
    "    losses, embeddings = run_epoch(data, labels, pars,\n",
    "                               net, 0, None,\n",
    "                               train=False,\n",
    "                               device=device,\n",
    "                               return_embeddings=True)\n",
    "\n",
    "\n",
    "    np.save(os.path.join(results_dir,f'embeddings_{name}.npy'), embeddings.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afce4ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: {'precision': 0.9382716049382716, 'recall': 0.9156626506024096, 'f1-score': 0.9268292682926829, 'support': 83}\n",
      "1: {'precision': 0.898876404494382, 'recall': 0.9523809523809523, 'f1-score': 0.9248554913294796, 'support': 84}\n",
      "2: {'precision': 1.0, 'recall': 0.963855421686747, 'f1-score': 0.9815950920245399, 'support': 83}\n",
      "accuracy: 0.944\n",
      "macro avg: {'precision': 0.9457160031442179, 'recall': 0.943966341556703, 'f1-score': 0.9444266172155675, 'support': 250}\n",
      "weighted avg: {'precision': 0.9455286447496185, 'recall': 0.944, 'f1-score': 0.9443483327120231, 'support': 250}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_command = f'phase2vec classify {eval_data_path} --feature-name embeddings --classifier logistic_regressor --results-dir {results_dir}'\n",
    "subprocess.call(clf_command,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accbbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
