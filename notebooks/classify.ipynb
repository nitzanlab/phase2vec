{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07927e79",
   "metadata": {},
   "source": [
    "# Classify embeddings\n",
    "\n",
    "This notebook can be used to recreate Fig. 4 from the manuscript. We compute and classify embeddings for several vector field datasets using a pretrained model. \n",
    "\n",
    "Our coding framework is based on a Click interface and we make use of that in this notebook by running the basic steps in the pipeline through shell commands.note\n",
    "\n",
    "**NOTE**: This notebook assumes you have a pretrained model. You can train a model using the notebook `train_and_eval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2789a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from src.utils import get_command_defaults, ensure_dir, write_yaml, update_yaml\n",
    "from src.train import load_model, train_model, run_epoch\n",
    "from src.data import load_dataset, SystemFamily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da8a5a",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "First, we generate the relevant evaluation data. There are three datasets immediately available here: (1) linear (e.g. fixed point classification), (2) conservative vs non-conservative and (3) incompressible vs compressible. You can comment out the `eval_data_names` definitions to switch between experiments.\n",
    "\n",
    "First, we set the data generation parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851c66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate evaluation data\n",
    "\n",
    "data_dir = '/home/mgricci/data/phase2vec' # Alter to change where all of the phase2vec data will be saved. \n",
    "\n",
    "# Switch between evaluation sets here\n",
    "# eval_data_names  = ['linear']\n",
    "# eval_data_names  = ['conservative', 'polynomial']\n",
    "# eval_data_names  = ['incompressible', 'polynomial']\n",
    "eval_data_names  = ['incompressible', 'conservative','polynomial']\n",
    "\n",
    "data_set_name = 'physics_3class'\n",
    "\n",
    "# Get class names\n",
    "eval_system_classes = []\n",
    "for system in [SystemFamily(data_name=name) for name in eval_data_names]:\n",
    "    eval_system_classes += [system.data_name + ' ' + str(i) for i in range(system.num_classes)]\n",
    "\n",
    "num_eval_classes = len(eval_system_classes)\n",
    "\n",
    "# Edit the number of total samples from each data set here.\n",
    "#By default, each set is divied further into a base and validation set at a 75/100 split. This can be altered below. \n",
    "num_eval_samples = 1000 # total number of train/val samples\n",
    "device            = 'cpu' # set to `cpu` if cuda not available\n",
    "\n",
    "eval_samplers    = ['uniform'] * len(eval_data_names)\n",
    "eval_props       = [str(1. / len(eval_data_names))] * len(eval_data_names)\n",
    "eval_system_names   = '-s ' +  ' -s '.join(eval_data_names)\n",
    "eval_samplers     = '-sp ' +  ' -sp '.join(eval_samplers)\n",
    "eval_props = '-c ' +  ' -c '.join(eval_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881af2c",
   "metadata": {},
   "source": [
    "Next, we call the actual shell commands for generating the data. These commands will make two directories, called `polynomial` and `classical`, corresponding to train and test sets, inside your `data_dir`. \n",
    "\n",
    "In order to alter the validation proportion, $p$, add the flag `--val-size <p>` where $p\\in (0,1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c484a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating incompressible data.\n",
      "Generating conservative data.\n",
      "Generating polynomial data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(f'phase2vec generate-dataset --data-dir {data_dir} --data-set-name {data_set_name} --num-samples {num_eval_samples} {eval_samplers} {eval_props} {eval_system_names}', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a948e1",
   "metadata": {},
   "source": [
    "## Load `phase2vec` encoder. \n",
    "\n",
    "We load the embedding CNN. By default, the net is saved in the folder `basic_train`, which is the default directory given in the `train_and_eval` notebook. \n",
    "\n",
    "* **model_type** (str): which of the pre-built architectures from _models.py to load. Make your own by combining modules from _modules.py \n",
    "* **latent_dim** (int): embedding dimension\n",
    "* Continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854d71bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Set net parameters\n",
    "from src.cli._cli import generate_net_config\n",
    "beta = 1e-3\n",
    "net_info = get_command_defaults(generate_net_config)\n",
    "model_type = net_info['net_class']\n",
    "model_save_dir  = os.path.join('/home/mgricci/phase2vec/', f'sparse_train_{beta}')\n",
    "\n",
    "# These parameters are not considered architectural parameters for the net, so we delete them before they're passed to the net builder. \n",
    "del net_info['net_class']\n",
    "del net_info['output_file']\n",
    "del net_info['pretrained_path']\n",
    "del net_info['ae']\n",
    "\n",
    "net = load_model(model_type, pretrained_path=os.path.join(model_save_dir, 'model.pt'), device=device, **net_info).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80583ef7",
   "metadata": {},
   "source": [
    "## Load data and compute embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17cca4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mgricci/results/phase2vec/physics_3class'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where is evaluation data stored? \n",
    "eval_data_path = os.path.join(data_dir, 'physics_3class')\n",
    "\n",
    "# Load evaluation data. \n",
    "X_train, X_test, y_train, y_test, p_train, p_test = load_dataset(eval_data_path)\n",
    "\n",
    "results_dir = f'/home/mgricci/results/phase2vec/{data_set_name}'\n",
    "ensure_dir(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84192ec",
   "metadata": {},
   "source": [
    "Now, we compute and save the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f5a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, (name, data, labels, pars) in enumerate(zip(['train', 'test'], [X_train, X_test],[y_train, y_test],[p_train, p_test])):\n",
    "\n",
    "    losses, embeddings = run_epoch(data, labels, pars,\n",
    "                               net, 0, None,\n",
    "                               train=False,\n",
    "                               device=device,\n",
    "                               return_embeddings=True)\n",
    "\n",
    "\n",
    "    np.save(os.path.join(results_dir,f'embeddings_{name}.npy'), embeddings.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afce4ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: {'precision': 0.9101123595505618, 'recall': 0.9642857142857143, 'f1-score': 0.9364161849710984, 'support': 84}\n",
      "1: {'precision': 0.927710843373494, 'recall': 0.927710843373494, 'f1-score': 0.927710843373494, 'support': 83}\n",
      "2: {'precision': 1.0, 'recall': 0.9397590361445783, 'f1-score': 0.9689440993788819, 'support': 83}\n",
      "accuracy: 0.944\n",
      "macro avg: {'precision': 0.9459410676413519, 'recall': 0.9439185312679289, 'f1-score': 0.9443570425744915, 'support': 250}\n",
      "weighted avg: {'precision': 0.9457977528089888, 'recall': 0.944, 'f1-score': 0.9443252791440778, 'support': 250}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_command = f'phase2vec classify {eval_data_path} --feature-name embeddings --classifier logistic_regressor --results-dir {results_dir}'\n",
    "subprocess.call(clf_command,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc242ba",
   "metadata": {},
   "source": [
    "## PCA representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e20c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "ensure_dir(results_dir)\n",
    "\n",
    "n_components = net.latent_dim\n",
    "for i, (name, data, labels, pars) in enumerate(zip(['train', 'test'], [X_train, X_test],[y_train, y_test],[p_train, p_test])):\n",
    "    pca = PCA(n_components)\n",
    "    z = pca.fit(data.reshape(len(data),-1)).transform(data.reshape(len(data),-1))\n",
    "    np.save(os.path.join(results_dir,f'pca_{name}.npy'), z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1cb33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: {'precision': 0.23943661971830985, 'recall': 0.20238095238095238, 'f1-score': 0.21935483870967745, 'support': 84}\n",
      "1: {'precision': 0.3157894736842105, 'recall': 0.3614457831325301, 'f1-score': 0.3370786516853933, 'support': 83}\n",
      "2: {'precision': 0.44047619047619047, 'recall': 0.4457831325301205, 'f1-score': 0.4431137724550898, 'support': 83}\n",
      "accuracy: 0.336\n",
      "macro avg: {'precision': 0.33190076129290363, 'recall': 0.336536622681201, 'f1-score': 0.3331824209500535, 'support': 250}\n",
      "weighted avg: {'precision': 0.33153090472660524, 'recall': 0.336, 'f1-score': 0.33272711062109206, 'support': 250}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_command = f'phase2vec classify {eval_data_path} --feature-name pca --classifier logistic_regressor --results-dir {results_dir}'\n",
    "subprocess.call(clf_command,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79155f",
   "metadata": {},
   "source": [
    "## Pars representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6c928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: {'precision': 0.3719512195121951, 'recall': 0.7261904761904762, 'f1-score': 0.4919354838709678, 'support': 84}\n",
      "1: {'precision': 0.0196078431372549, 'recall': 0.012048192771084338, 'f1-score': 0.01492537313432836, 'support': 83}\n",
      "2: {'precision': 1.0, 'recall': 0.42168674698795183, 'f1-score': 0.5932203389830509, 'support': 83}\n",
      "accuracy: 0.388\n",
      "macro avg: {'precision': 0.46385302088315, 'recall': 0.38664180531650416, 'f1-score': 0.3666937319961157, 'support': 250}\n",
      "weighted avg: {'precision': 0.4634854136776662, 'recall': 0.388, 'f1-score': 0.36719469900361507, 'support': 250}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(f'cp {os.path.join(data_dir, data_set_name,\"p_*npy\")} {results_dir}/', shell=True)\n",
    "clf_command = f'phase2vec classify {eval_data_path} --feature-name p --classifier logistic_regressor --results-dir {results_dir}'\n",
    "subprocess.call(clf_command,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa0564d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a9e037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
