{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07927e79",
   "metadata": {},
   "source": [
    "# Classify embeddings\n",
    "\n",
    "This notebook can be used to recreate Fig. 4 from the manuscript. We compute and classify embeddings for several vector field datasets using a pretrained model. \n",
    "\n",
    "Our coding framework is based on a Click interface and we make use of that in this notebook by running the basic steps in the pipeline through shell commands.note\n",
    "\n",
    "**NOTE**: This notebook assumes you have a pretrained model. You can train a model using the notebook `train_and_eval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2789a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from phase2vec.utils import get_command_defaults, ensure_dir, write_yaml, update_yaml\n",
    "from phase2vec.train import load_model, train_model, run_epoch\n",
    "from phase2vec.data import load_dataset, SystemFamily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da8a5a",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "First, we generate the relevant evaluation data. There are three datasets immediately available here: (1) linear (e.g. fixed point classification), (2) conservative vs non-conservative and (3) incompressible vs compressible. You can comment out the `eval_data_names` definitions to switch between experiments.\n",
    "\n",
    "First, we set the data generation parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate evaluation data\n",
    "outdir = '../' # Alter to change where all of the phase2vec data will be saved. \n",
    "data_dir = os.path.join(outdir, 'data') \n",
    "\n",
    "# Switch between evaluation sets here\n",
    "eval_data_names  = ['linear']\n",
    "# eval_data_names  = ['conservative', 'polynomial']\n",
    "# eval_data_names  = ['incompressible', 'polynomial']\n",
    "# eval_data_names  = ['incompressible', 'conservative','polynomial']\n",
    "\n",
    "# data_set_name = 'physics_3class'\n",
    "data_set_name = 'linear'\n",
    "\n",
    "# Get class names\n",
    "eval_system_classes = []\n",
    "for system in [SystemFamily(data_name=name) for name in eval_data_names]:\n",
    "    eval_system_classes += [system.data_name + ' ' + str(i) for i in range(system.num_classes)]\n",
    "\n",
    "num_eval_classes = len(eval_system_classes)\n",
    "\n",
    "# Edit the number of total samples from each data set here.\n",
    "#By default, each set is divied further into a base and validation set at a 75/100 split. This can be altered below. \n",
    "num_eval_samples = 1000 # total number of train/val samples\n",
    "device            = 'cpu' # set to `cpu` if cuda not available\n",
    "\n",
    "eval_samplers    = ['uniform'] * len(eval_data_names)\n",
    "eval_props       = [str(1. / len(eval_data_names))] * len(eval_data_names)\n",
    "eval_system_names   = '-s ' +  ' -s '.join(eval_data_names)\n",
    "eval_samplers     = '-sp ' +  ' -sp '.join(eval_samplers)\n",
    "eval_props = '-c ' +  ' -c '.join(eval_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881af2c",
   "metadata": {},
   "source": [
    "Next, we call the actual shell commands for generating the data. These commands will make two directories, called `polynomial` and `classical`, corresponding to train and test sets, inside your `data_dir`. \n",
    "\n",
    "In order to alter the validation proportion, $p$, add the flag `--val-size <p>` where $p\\in (0,1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c484a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call(f'phase2vec generate-dataset --data-dir {data_dir} --data-set-name {data_set_name} --num-samples {num_eval_samples} {eval_samplers} {eval_props} {eval_system_names}', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a948e1",
   "metadata": {},
   "source": [
    "## Load `phase2vec` encoder. \n",
    "\n",
    "We load the embedding CNN. By default, the net is saved in the folder `basic_train`, which is the default directory given in the `train_and_eval` notebook. \n",
    "\n",
    "* **model_type** (str): which of the pre-built architectures from _models.py to load. Make your own by combining modules from _modules.py \n",
    "* **latent_dim** (int): embedding dimension\n",
    "* Continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d71bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Set net parameters\n",
    "from phase2vec.cli._cli import generate_net_config\n",
    "beta = 1e-3 # Edit this to match the beta you used during training\n",
    "net_info = get_command_defaults(generate_net_config)\n",
    "model_type = net_info['net_class']\n",
    "model_save_dir  = os.path.join(os.path.expanduser('~'),'phase2vec/', f'sparse_train_{beta}')\n",
    "\n",
    "# These parameters are not considered architectural parameters for the net, so we delete them before they're passed to the net builder. \n",
    "del net_info['net_class']\n",
    "del net_info['output_file']\n",
    "del net_info['pretrained_path']\n",
    "del net_info['ae']\n",
    "\n",
    "net = load_model(model_type, pretrained_path=os.path.join(model_save_dir, 'model.pt'), device=device, **net_info).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80583ef7",
   "metadata": {},
   "source": [
    "## Load data and compute embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cca4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is evaluation data stored? \n",
    "eval_data_path = os.path.join(data_dir, data_set_name)\n",
    "\n",
    "# Load evaluation data. \n",
    "X_train, X_test, y_train, y_test, p_train, p_test = load_dataset(eval_data_path)\n",
    "\n",
    "results_dir = os.path.join(os.path.expanduser('~'),f'phase2vec/{data_set_name}')\n",
    "ensure_dir(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84192ec",
   "metadata": {},
   "source": [
    "Now, we compute and save the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, (name, data, labels, pars) in enumerate(zip(['train', 'test'], [X_train, X_test],[y_train, y_test],[p_train, p_test])):\n",
    "\n",
    "    losses, embeddings = run_epoch(data, labels, pars,\n",
    "                               net, 0, None,\n",
    "                               train=False,\n",
    "                               device=device,\n",
    "                               return_embeddings=True)\n",
    "\n",
    "\n",
    "    np.save(os.path.join(results_dir,f'embeddings_{name}.npy'), embeddings.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can take between 5-10 minutes depending on the number of classes and samples.  \n",
    "clf_command = f'phase2vec classify {eval_data_path} --feature-name embeddings --classifier logistic_regressor --results-dir {results_dir}'\n",
    "subprocess.call(clf_command,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc242ba",
   "metadata": {},
   "source": [
    "## PCA representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "ensure_dir(results_dir)\n",
    "\n",
    "n_components = net.latent_dim\n",
    "for i, (name, data, labels, pars) in enumerate(zip(['train', 'test'], [X_train, X_test],[y_train, y_test],[p_train, p_test])):\n",
    "    pca = PCA(n_components)\n",
    "    data = data.reshape(len(data),-1)\n",
    "    z = pca.fit_transform(data)\n",
    "    np.save(os.path.join(results_dir,f'pca_{name}.npy'), z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1cb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_command = f'phase2vec classify {eval_data_path} --feature-name pca --classifier logistic_regressor --results-dir {results_dir}'\n",
    "subprocess.call(clf_command,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79155f",
   "metadata": {},
   "source": [
    "## Pars representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call(f'cp {os.path.join(data_dir, data_set_name,\"p_*npy\")} {results_dir}/', shell=True)\n",
    "clf_command = f'phase2vec classify {eval_data_path} --feature-name p --classifier logistic_regressor --results-dir {results_dir}'\n",
    "subprocess.call(clf_command,shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
